[{"path":[]},{"path":"https://milevavantuyl.github.io/AIF360/CODEOFCONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/CODEOFCONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://milevavantuyl.github.io/AIF360/CODEOFCONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to the AIF360 R package","title":"Contributing to the AIF360 R package","text":"guide divided three main parts: Filing bug report feature request issue. Suggesting change via pull request. New features enhancements AIF360 functionality. ’re familiar git GitHub, please start reading http://r-pkgs..co.nz/git.html Please note AIF360 R package released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/CONTRIBUTING.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"Contributing to the AIF360 R package","text":"find bug, please search GitHub Issues ensure bug already reported. ’re unable find open issue addressing problem, open new one. Please include title clear description, much relevant information possible (required packages, data, etc.), code sample replicate issue.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to the AIF360 R package","text":"contribute change AIF360 R package, follow steps: Create branch git make changes. Push branch GitHub open new pull request (PR). Ensure PR description clearly describes problem solution. Include relevant issue number applicable.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/CONTRIBUTING.html","id":"new-features","dir":"","previous_headings":"","what":"New Features","title":"Contributing to the AIF360 R package","text":"AIF360 R package part AI Fairness 360, developed extensibility mind. wish suggest new metrics, explainers, algorithms datasets. Please get touch Slack (invitation )!","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"Apache License","title":"Apache License","text":"Version 2.0, January 2004 <http://www.apache.org/licenses/>","code":""},{"path":[]},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"1-definitions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"1. Definitions","title":"Apache License","text":"“License” shall mean terms conditions use, reproduction, distribution defined Sections 1 9 document. “Licensor” shall mean copyright owner entity authorized copyright owner granting License. “Legal Entity” shall mean union acting entity entities control, controlled , common control entity. purposes definition, “control” means () power, direct indirect, cause direction management entity, whether contract otherwise, (ii) ownership fifty percent (50%) outstanding shares, (iii) beneficial ownership entity. “” (“”) shall mean individual Legal Entity exercising permissions granted License. “Source” form shall mean preferred form making modifications, including limited software source code, documentation source, configuration files. “Object” form shall mean form resulting mechanical transformation translation Source form, including limited compiled object code, generated documentation, conversions media types. “Work” shall mean work authorship, whether Source Object form, made available License, indicated copyright notice included attached work (example provided Appendix ). “Derivative Works” shall mean work, whether Source Object form, based (derived ) Work editorial revisions, annotations, elaborations, modifications represent, whole, original work authorship. purposes License, Derivative Works shall include works remain separable , merely link (bind name) interfaces , Work Derivative Works thereof. “Contribution” shall mean work authorship, including original version Work modifications additions Work Derivative Works thereof, intentionally submitted Licensor inclusion Work copyright owner individual Legal Entity authorized submit behalf copyright owner. purposes definition, “submitted” means form electronic, verbal, written communication sent Licensor representatives, including limited communication electronic mailing lists, source code control systems, issue tracking systems managed , behalf , Licensor purpose discussing improving Work, excluding communication conspicuously marked otherwise designated writing copyright owner “Contribution.” “Contributor” shall mean Licensor individual Legal Entity behalf Contribution received Licensor subsequently incorporated within Work.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"2-grant-of-copyright-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"2. Grant of Copyright License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable copyright license reproduce, prepare Derivative Works , publicly display, publicly perform, sublicense, distribute Work Derivative Works Source Object form.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"3-grant-of-patent-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"3. Grant of Patent License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable (except stated section) patent license make, made, use, offer sell, sell, import, otherwise transfer Work, license applies patent claims licensable Contributor necessarily infringed Contribution(s) alone combination Contribution(s) Work Contribution(s) submitted. institute patent litigation entity (including cross-claim counterclaim lawsuit) alleging Work Contribution incorporated within Work constitutes direct contributory patent infringement, patent licenses granted License Work shall terminate date litigation filed.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"4-redistribution","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"4. Redistribution","title":"Apache License","text":"may reproduce distribute copies Work Derivative Works thereof medium, without modifications, Source Object form, provided meet following conditions: () must give recipients Work Derivative Works copy License; (b) must cause modified files carry prominent notices stating changed files; (c) must retain, Source form Derivative Works distribute, copyright, patent, trademark, attribution notices Source form Work, excluding notices pertain part Derivative Works; (d) Work includes “NOTICE” text file part distribution, Derivative Works distribute must include readable copy attribution notices contained within NOTICE file, excluding notices pertain part Derivative Works, least one following places: within NOTICE text file distributed part Derivative Works; within Source form documentation, provided along Derivative Works; , within display generated Derivative Works, wherever third-party notices normally appear. contents NOTICE file informational purposes modify License. may add attribution notices within Derivative Works distribute, alongside addendum NOTICE text Work, provided additional attribution notices construed modifying License. may add copyright statement modifications may provide additional different license terms conditions use, reproduction, distribution modifications, Derivative Works whole, provided use, reproduction, distribution Work otherwise complies conditions stated License.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"5-submission-of-contributions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"5. Submission of Contributions","title":"Apache License","text":"Unless explicitly state otherwise, Contribution intentionally submitted inclusion Work Licensor shall terms conditions License, without additional terms conditions. Notwithstanding , nothing herein shall supersede modify terms separate license agreement may executed Licensor regarding Contributions.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"6-trademarks","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"6. Trademarks","title":"Apache License","text":"License grant permission use trade names, trademarks, service marks, product names Licensor, except required reasonable customary use describing origin Work reproducing content NOTICE file.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"7-disclaimer-of-warranty","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"7. Disclaimer of Warranty","title":"Apache License","text":"Unless required applicable law agreed writing, Licensor provides Work (Contributor provides Contributions) “” BASIS, WITHOUT WARRANTIES CONDITIONS KIND, either express implied, including, without limitation, warranties conditions TITLE, NON-INFRINGEMENT, MERCHANTABILITY, FITNESS PARTICULAR PURPOSE. solely responsible determining appropriateness using redistributing Work assume risks associated exercise permissions License.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"8-limitation-of-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"8. Limitation of Liability","title":"Apache License","text":"event legal theory, whether tort (including negligence), contract, otherwise, unless required applicable law (deliberate grossly negligent acts) agreed writing, shall Contributor liable damages, including direct, indirect, special, incidental, consequential damages character arising result License use inability use Work (including limited damages loss goodwill, work stoppage, computer failure malfunction, commercial damages losses), even Contributor advised possibility damages.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"9-accepting-warranty-or-additional-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"9. Accepting Warranty or Additional Liability","title":"Apache License","text":"redistributing Work Derivative Works thereof, may choose offer, charge fee , acceptance support, warranty, indemnity, liability obligations /rights consistent License. However, accepting obligations, may act behalf sole responsibility, behalf Contributor, agree indemnify, defend, hold Contributor harmless liability incurred , claims asserted , Contributor reason accepting warranty additional liability. END TERMS CONDITIONS","code":""},{"path":"https://milevavantuyl.github.io/AIF360/LICENSE.html","id":"appendix-how-to-apply-the-apache-license-to-your-work","dir":"","previous_headings":"","what":"APPENDIX: How to apply the Apache License to your work","title":"Apache License","text":"apply Apache License work, attach following boilerplate notice, fields enclosed brackets [] replaced identifying information. (Don’t include brackets!) text enclosed appropriate comment syntax file format. also recommend file class name description purpose included “printed page” copyright notice easier identification within third-party archives.","code":"Copyright 2020-2021 The AI Fairness 360 (AIF360) Authors  Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."},{"path":"https://milevavantuyl.github.io/AIF360/articles/aif360_intro.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Introduction to AI Fairness 360","text":"AI Fairness 360 (AIF360) package provides comprehensive set tools detect mitigate bias machine learning models. package includes: Built-datasets understand concepts fairness, Metrics models testing biases, Explanations metrics, Algorithms mitigate bias datasets models. vignette introduces core components AIF360 package demonstrates toolkit can used mitigate bias using real-world dataset. get started, can run following commands: issues occur, refer installation troubleshooting sections README GitHub Repository.","code":"# Activate Python environment reticulate::use_condaenv(condaenv = \"r-test\", required = TRUE) library(aif360) load_aif360_lib()"},{"path":"https://milevavantuyl.github.io/AIF360/articles/aif360_intro.html","id":"data-adult-census-income-dataset","dir":"Articles","previous_headings":"","what":"Data: Adult Census Income Dataset","title":"Introduction to AI Fairness 360","text":"Adult Census Income Dataset one four datasets included AIF360 package. record consists census data individual goal predict whether individual’s income exceeds $50k per year. Details dataset documented ?adult_dataset.","code":"# Assumes the Adult data files have been manually added to the correct path adult <- adult_dataset()"},{"path":"https://milevavantuyl.github.io/AIF360/articles/aif360_intro.html","id":"protected-attributes-privileged-groups-and-unprivileged-groups","dir":"Articles","previous_headings":"Data: Adult Census Income Dataset","what":"Protected Attributes, Privileged Groups, and Unprivileged Groups","title":"Introduction to AI Fairness 360","text":"given problem, must tailor bias detection mitigation toolkit accordingly. done defining set attributes referred protected attributes indicate particular bias (biases) interest. Additionally, privileged groups unprivileged groups specify groups historically systematic advantage disadvantage respectively. example, protected attribute “sex”, “1” (male) “0” (female) values privileged unprivileged groups respectively.","code":"# Protected attribute selection protected_attribute <- \"sex\" # Privileged and Unprivileged Groups # The input is a list containing the protected attribute name and the value  # indicating the privileged or unprivileged group respectively  # Privileged Group: Sex is the protected attribute and \"1\" indicates male  privileged_groups <- list(protected_attribute, 1)   # Unprivileged Group: Sex is the protected attribute and \"0\" indicates female  unprivileged_groups <- list(protected_attribute, 0)"},{"path":"https://milevavantuyl.github.io/AIF360/articles/aif360_intro.html","id":"train-test-split","dir":"Articles","previous_headings":"Data: Adult Census Income Dataset","what":"Train-Test Split","title":"Introduction to AI Fairness 360","text":"applying bias detection mitigation techniques, split original dataset training testing datasets. can train-test split via split method provided AIF360 dataset object: use training dataset tutorial, typical machine learning workflows testing dataset used assessing model’s accuracy fairness.","code":"set.seed(1234)  # Apply a 70-30 train-test split  adult_split <- adult$split(num_or_size_splits = list(0.70)) adult_train <- adult_split[[1]] adult_test  <- adult_split[[2]]"},{"path":"https://milevavantuyl.github.io/AIF360/articles/aif360_intro.html","id":"bias-detection","dir":"Articles","previous_headings":"","what":"Bias Detection","title":"Introduction to AI Fairness 360","text":"can now use AIF360 detect bias dataset. , toolkit provides wide selection fairness metrics choose based whether group fairness, individual fairness, group individual fairness desired given application. Explore available metrics documentation via ?binary_label_dataset_metric. application, concerned group fairness. means want statistical measure equal across unprivileged group (females) privileged group (males). particular, use Statistical Parity Difference metric, computed difference rate favorable outcomes received unprivileged group privileged group. ideal value Statistical Parity Difference metric 0.0, acceptable range generally -0.1 0.1. example, metric value -0.1977357, outside acceptable range Statistical Parity Difference metric. Thus, privileged unprivileged groups selected equal rates. Meanwhile, negative value indicates unprivileged group disadvantage.","code":"# Initialize binary label dataset metric class metric_train <- binary_label_dataset_metric(adult_train,                                             privileged_groups = privileged_groups,                                             unprivileged_groups = unprivileged_groups) # Access `Statistical Parity Difference` metric  metric_train$statistical_parity_difference() #> [1] -0.1977357"},{"path":"https://milevavantuyl.github.io/AIF360/articles/aif360_intro.html","id":"bias-mitigation","dir":"Articles","previous_headings":"","what":"Bias Mitigation","title":"Introduction to AI Fairness 360","text":"Bias can introduced system three main ways: training dataset may biased, algorithm creates model may biased, testing dataset may biased. AIF360 toolkit includes pre-processing, -processing, post-processing bias mitigation techniques handle three scenarios respectively. previous “Bias Detection” stage example, observed unprivileged group disadvantage training dataset. step, apply Reweighing algorithm documented ?reweighing. Reweighing algorithm pre-processing technique transforms original dataset achieve greater fairness privileged unprivileged groups prior creation model.","code":"# Pre-processing Algorithm: Reweighing mitigate_reweighing <- reweighing(privileged_groups = privileged_groups,                                   unprivileged_groups = unprivileged_groups) adult_transformed <- mitigate_reweighing$fit_transform(adult_train)"},{"path":"https://milevavantuyl.github.io/AIF360/articles/aif360_intro.html","id":"effect-of-bias-mitigation-procedure","dir":"Articles","previous_headings":"","what":"Effect of Bias Mitigation Procedure","title":"Introduction to AI Fairness 360","text":"can now check effective Reweighing algorithm previous step mitigating bias training dataset. bias mitigation step effective metric value now -2.775558e-17, close 0.0. Thus, went dataset unprivileged group initially disadvantage one equality terms Statistical Parity Difference metric.","code":"# Initialize binary label dataset metric class with the transformed dataset metric_train <- binary_label_dataset_metric(adult_transformed,                                             privileged_groups = privileged_groups,                                             unprivileged_groups = unprivileged_groups)  # Access `Statistical Parity Difference` metric metric_train$statistical_parity_difference() #> [1] -2.775558e-17"},{"path":"https://milevavantuyl.github.io/AIF360/articles/aif360_intro.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Introduction to AI Fairness 360","text":"vignette provides initial introduction concepts bias detection mitigation machine learning models using AI Fairness 360 toolkit. noted vignette, AI Fairness toolkit provides wide array metrics bias mitigation algorithms choose . Future vignettes along AIF360 website documentation also discuss use metrics mitigation algorithms detail.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gabriela de Queiroz. Author. Stacey Ronaghan. Author. Saishruthi Swaminathan. Author, maintainer.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"de Queiroz G, Ronaghan S, Swaminathan S (2022). aif360: Help Detect Mitigate Bias Machine Learning Models. https://github.com/Trusted-AI/AIF360, https://milevavantuyl.github.io/AIF360/.","code":"@Manual{,   title = {aif360: Help Detect and Mitigate Bias in Machine Learning Models},   author = {Gabriela {de Queiroz} and Stacey Ronaghan and Saishruthi Swaminathan},   year = {2022},   note = {https://github.com/Trusted-AI/AIF360, https://milevavantuyl.github.io/AIF360/}, }"},{"path":[]},{"path":"https://milevavantuyl.github.io/AIF360/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Help Detect and Mitigate Bias in Machine Learning Models","text":"AI Fairness 360 toolkit open-source library help detect mitigate bias machine learning models. AI Fairness 360 R package includes comprehensive set metrics datasets models test biases, explanations metrics, algorithms mitigate bias datasets models.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Help Detect and Mitigate Bias in Machine Learning Models","text":"Install CRAN version: install development version GitHub: , use install_aif360() function install AIF360:","code":"install.packages(\"aif360\") # install.packages(\"devtools\") devtools::install_github(\"Trusted-AI/AIF360/aif360/aif360-r\") library(aif360) install_aif360()"},{"path":"https://milevavantuyl.github.io/AIF360/index.html","id":"installation-methods","dir":"","previous_headings":"","what":"Installation methods","title":"Help Detect and Mitigate Bias in Machine Learning Models","text":"AIF360 distributed Python package needs installed within Python environment system. default, install_aif360() function attempts install AIF360 within isolated Python environment (“r-reticulate”). can check using reticulate::conda_python() reticulate::py_config()","code":""},{"path":"https://milevavantuyl.github.io/AIF360/index.html","id":"suggested-steps","dir":"","previous_headings":"Installation methods","what":"Suggested steps","title":"Help Detect and Mitigate Bias in Machine Learning Models","text":"Install reticulate check miniconda installed. , go step 2. get error: Error: Unable find conda binary. Anaconda installed?, please install miniconda everything worked, get message: * Miniconda successfully installed '/home/rstudio/.local/share/r-miniconda'. can double check: get something like : can create new conda env configure version Python use: Check everything working reticulate::py_config(). haven’t yet, please install aif360 package install.packages(\"aif360\") install aif360 dependencies Note step take minutes R session restart. can now activate Python environment","code":"install.packages(\"reticulate\") reticulate::conda_list() reticulate::install_miniconda() reticulate::conda_list() name                                                              python 1  r-miniconda                   /home/rstudio/.local/share/r-miniconda/bin/python 2 r-reticulate /home/rstudio/.local/share/r-miniconda/envs/r-reticulate/bin/python reticulate::conda_create(envname = \"r-test\") reticulate::use_miniconda(condaenv = \"r-test\", required = TRUE) aif360::install_aif360(envname = \"r-test\") reticulate::use_miniconda(condaenv = \"r-test\", required = TRUE)"},{"path":"https://milevavantuyl.github.io/AIF360/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Help Detect and Mitigate Bias in Machine Learning Models","text":"","code":"library(aif360) load_aif360_lib() # load a toy dataset data <- data.frame(\"feature1\" = c(0,0,1,1,1,1,0,1,1,0),                    \"feature2\" = c(0,1,0,1,1,0,0,0,0,1),                    \"label\" = c(1,0,0,1,0,0,1,0,1,1))  # format the dataset formatted_dataset <- aif360::binary_label_dataset(data_path = data,                                           favor_label = 0,                                           unfavor_label = 1,                                           unprivileged_protected_attribute = 0,                                           privileged_protected_attribute = 1,                                           target_column = \"label\",                                           protected_attribute = \"feature1\")"},{"path":"https://milevavantuyl.github.io/AIF360/index.html","id":"troubleshooting","dir":"","previous_headings":"","what":"Troubleshooting","title":"Help Detect and Mitigate Bias in Machine Learning Models","text":"encounter errors installation process, look issue try solutions.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/index.html","id":"locked-binding","dir":"","previous_headings":"Troubleshooting","what":"Locked binding","title":"Help Detect and Mitigate Bias in Machine Learning Models","text":"get error: change value locked binding, please restart R session. try reactivating Python environment running following commands exactly :","code":"library(aif360)  load_aif360_lib()"},{"path":"https://milevavantuyl.github.io/AIF360/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Help Detect and Mitigate Bias in Machine Learning Models","text":"’d like contribute development aif360, please read guidelines. Please note aif360 project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/adult_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Adult Census Income Dataset — adult_dataset","title":"Adult Census Income Dataset — adult_dataset","text":"Adult Census Income Dataset","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/adult_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adult Census Income Dataset — adult_dataset","text":"","code":"adult_dataset()"},{"path":"https://milevavantuyl.github.io/AIF360/reference/adversarial_debiasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Adversarial Debiasing — adversarial_debiasing","title":"Adversarial Debiasing — adversarial_debiasing","text":"Adversarial debiasing -processing technique learns classifier maximize prediction accuracy  simultaneously reduce adversary's ability determine protected attribute predictions","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/adversarial_debiasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adversarial Debiasing — adversarial_debiasing","text":"","code":"adversarial_debiasing(   unprivileged_groups,   privileged_groups,   scope_name = \"current\",   sess = tf$compat$v1$Session(),   seed = NULL,   adversary_loss_weight = 0.1,   num_epochs = 50L,   batch_size = 128L,   classifier_num_hidden_units = 200L,   debias = TRUE )"},{"path":"https://milevavantuyl.github.io/AIF360/reference/adversarial_debiasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adversarial Debiasing — adversarial_debiasing","text":"unprivileged_groups list two values: column protected class value indicating representation unprivileged group. privileged_groups list two values: column protected class value indicating representation privileged group. scope_name Scope name tensorflow variables. sess tensorflow session seed Seed make predict repeatable. , NULL, must integer. adversary_loss_weight Hyperparameter chooses strength adversarial loss. num_epochs Number training epochs. Must integer. batch_size Batch size. Must integer. classifier_num_hidden_units Number hidden units classifier model. Must integer. debias Learn classifier without debiasing.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/adversarial_debiasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adversarial Debiasing — adversarial_debiasing","text":"","code":"if (FALSE) { load_aif360_lib() ad <- adult_dataset() p <- list(\"race\", 1) u <- list(\"race\", 0)  sess <- tf$compat$v1$Session()  plain_model <- adversarial_debiasing(privileged_groups = p,                                      unprivileged_groups = u,                                      scope_name = \"debiased_classifier\",                                      debias = TRUE,                                      sess = sess)  plain_model$fit(ad) ad_nodebiasing <- plain_model$predict(ad) }"},{"path":"https://milevavantuyl.github.io/AIF360/reference/bank_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Bank Dataset — bank_dataset","title":"Bank Dataset — bank_dataset","text":"Bank Dataset","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/bank_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bank Dataset — bank_dataset","text":"","code":"bank_dataset()"},{"path":"https://milevavantuyl.github.io/AIF360/reference/binary_label_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"AIF360 dataset — binary_label_dataset","title":"AIF360 dataset — binary_label_dataset","text":"Function create AIF compatible dataset.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/binary_label_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AIF360 dataset — binary_label_dataset","text":"","code":"binary_label_dataset(data_path,  favor_label, unfavor_label,                      unprivileged_protected_attribute,                      privileged_protected_attribute,                      target_column, protected_attribute)"},{"path":"https://milevavantuyl.github.io/AIF360/reference/binary_label_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AIF360 dataset — binary_label_dataset","text":"data_path Path input CSV file R dataframe. favor_label Label value considered favorable (.e. “positive”). unfavor_label Label value considered unfavorable (.e. “negative”). unprivileged_protected_attribute unprotected attribute value considered privileged fairness perspective. privileged_protected_attribute protected attribute value considered privileged fairness perspective. target_column Name describing label. protected_attribute feature fairness desired.","code":""},{"path":[]},{"path":"https://milevavantuyl.github.io/AIF360/reference/binary_label_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"AIF360 dataset — binary_label_dataset","text":"","code":"if (FALSE) { load_aif360_lib() # Input dataset data <- data.frame(\"feat\" = c(0,0,1,1,1,1,0,1,1,0), \"label\" = c(1,0,0,1,0,0,1,0,1,1)) # Create aif compatible input dataset act <- aif360::binary_label_dataset(data_path = data,  favor_label=0, unfavor_label=1,                             unprivileged_protected_attribute=0,                             privileged_protected_attribute=1,                             target_column=\"label\", protected_attribute=\"feat\") }"},{"path":"https://milevavantuyl.github.io/AIF360/reference/binary_label_dataset_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary Label Dataset Metric — binary_label_dataset_metric","title":"Binary Label Dataset Metric — binary_label_dataset_metric","text":"Class computing metrics aif360 compatible dataset binary labels.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/binary_label_dataset_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary Label Dataset Metric — binary_label_dataset_metric","text":"","code":"binary_label_dataset_metric(dataset, privileged_groups, unprivileged_groups)"},{"path":"https://milevavantuyl.github.io/AIF360/reference/binary_label_dataset_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary Label Dataset Metric — binary_label_dataset_metric","text":"dataset aif360 compatible dataset. privileged_groups Privileged groups. List containing privileged protected attribute name value privileged protected attribute. unprivileged_groups Unprivileged groups. List containing unprivileged protected attribute name value unprivileged protected attribute.","code":""},{"path":[]},{"path":"https://milevavantuyl.github.io/AIF360/reference/binary_label_dataset_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binary Label Dataset Metric — binary_label_dataset_metric","text":"","code":"if (FALSE) { load_aif360_lib() # Load the adult dataset adult_dataset <- adult_dataset()  # Define the groups privileged_groups <- list(\"race\", 1) unprivileged_groups <- list(\"race\", 0)  # Metric for Binary Label Dataset bm <- binary_label_dataset_metric(dataset = adult_dataset,                                   privileged_groups = privileged_groups,                                   unprivileged_groups = unprivileged_groups)  # Difference in mean outcomes between unprivileged and privileged groups bm$mean_difference() }"},{"path":"https://milevavantuyl.github.io/AIF360/reference/classification_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Classification Metric — classification_metric","title":"Classification Metric — classification_metric","text":"Class computing metrics based two BinaryLabelDatasets. first dataset original one second output classification transformer (similar)","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/classification_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classification Metric — classification_metric","text":"","code":"classification_metric(dataset, classified_dataset, unprivileged_groups, privileged_groups)"},{"path":"https://milevavantuyl.github.io/AIF360/reference/classification_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classification Metric — classification_metric","text":"dataset (BinaryLabelDataset) Dataset containing ground-truth labels classified_dataset (BinaryLabelDataset) Dataset containing predictions unprivileged_groups Unprivileged groups. List containing unprivileged protected attribute name value unprivileged protected attribute. privileged_groups Privileged groups. List containing privileged protected attribute name value privileged protected attribute.","code":""},{"path":[]},{"path":"https://milevavantuyl.github.io/AIF360/reference/classification_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classification Metric — classification_metric","text":"","code":"if (FALSE) { load_aif360_lib() # Input dataset data <- data.frame(\"feat\" = c(0,0,1,1,1,1,0,1,1,0), \"label\" = c(1,0,0,1,0,0,1,0,1,1)) # Create aif compatible input dataset act <- aif360::binary_label_dataset(data_path = data,  favor_label=0, unfavor_label=1,                             unprivileged_protected_attribute=0,                             privileged_protected_attribute=1,                             target_column=\"label\", protected_attribute=\"feat\") # Classified dataset pred_data <- data.frame(\"feat\" = c(0,0,1,1,1,1,0,1,1,0), \"label\" = c(1,0,1,1,1,0,1,0,0,1)) # Create aif compatible classified dataset pred <- aif360::binary_label_dataset(data_path = pred_data,  favor_label=0, unfavor_label=1,                              unprivileged_protected_attribute=0,                              privileged_protected_attribute=1,                              target_column=\"label\", protected_attribute=\"feat\") # Create an instance of classification metric cm <- classification_metric(act, pred, list('feat', 1), list('feat', 0)) # Access metric functions cm$accuracy() }"},{"path":"https://milevavantuyl.github.io/AIF360/reference/compas_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Compas Dataset — compas_dataset","title":"Compas Dataset — compas_dataset","text":"Compas Dataset","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/compas_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compas Dataset — compas_dataset","text":"","code":"compas_dataset()"},{"path":"https://milevavantuyl.github.io/AIF360/reference/disparate_impact_remover.html","id":null,"dir":"Reference","previous_headings":"","what":"Disparate Impact Remover — disparate_impact_remover","title":"Disparate Impact Remover — disparate_impact_remover","text":"Disparate impact remover preprocessing technique edits feature values increase group fairness preserving rank-ordering within groups","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/disparate_impact_remover.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Disparate Impact Remover — disparate_impact_remover","text":"","code":"disparate_impact_remover(repair_level = 1.0, sensitive_attribute = '')"},{"path":"https://milevavantuyl.github.io/AIF360/reference/disparate_impact_remover.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Disparate Impact Remover — disparate_impact_remover","text":"repair_level Repair amount. 0.0 repair 1.0 full repair. sensitive_attribute Single protected attribute repair.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/disparate_impact_remover.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Disparate Impact Remover — disparate_impact_remover","text":"","code":"if (FALSE) { # An example using the Adult Dataset load_aif360_lib() ad <- adult_dataset() p <- list(\"race\", 1) u <- list(\"race\", 0)  di <- disparate_impact_remover(repair_level = 1.0, sensitive_attribute = \"race\") rp <- di$fit_transform(ad)  di_2 <- disparate_impact_remover(repair_level = 0.8, sensitive_attribute = \"race\") rp_2 <- di_2$fit_transform(ad) }"},{"path":"https://milevavantuyl.github.io/AIF360/reference/german_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"German Dataset — german_dataset","title":"German Dataset — german_dataset","text":"German Dataset","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/german_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"German Dataset — german_dataset","text":"","code":"german_dataset()"},{"path":"https://milevavantuyl.github.io/AIF360/reference/install_aif360.html","id":null,"dir":"Reference","previous_headings":"","what":"Install aif360 and its dependencies — install_aif360","title":"Install aif360 and its dependencies — install_aif360","text":"Install aif360 dependencies","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/install_aif360.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install aif360 and its dependencies — install_aif360","text":"","code":"install_aif360(   method = c(\"auto\", \"virtualenv\", \"conda\"),   conda = \"auto\",   version = \"default\",   envname = NULL,   extra_packages = NULL,   restart_session = TRUE,   conda_python_version = \"3.7\",   ... )"},{"path":"https://milevavantuyl.github.io/AIF360/reference/install_aif360.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install aif360 and its dependencies — install_aif360","text":"method Installation method. default, \"auto\" automatically finds method work local environment. Change default force specific installation method. Note \"virtualenv\" method available Windows. Note also since command runs without privilege \"system\" method available Windows. conda path conda executable. Use \"auto\" allow reticulate automatically find appropriate conda binary. See Finding Conda conda_binary() details. version AIF360 version install. Specify \"default\" install latest release. envname Name Python environment install within extra_packages Additional Python packages install. restart_session Restart R session installing (note occur within RStudio). conda_python_version python version installed created conda environment. Python 3.6 installed default. ... arguments passed [reticulate::conda_install()] [reticulate::virtualenv_install()].","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/law_school_gpa_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Law School GPA Dataset — law_school_gpa_dataset","title":"Law School GPA Dataset — law_school_gpa_dataset","text":"Law School GPA Dataset","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/law_school_gpa_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Law School GPA Dataset — law_school_gpa_dataset","text":"","code":"law_school_gpa_dataset()"},{"path":[]},{"path":"https://milevavantuyl.github.io/AIF360/reference/load_aif360_lib.html","id":null,"dir":"Reference","previous_headings":"","what":"load functions — load_aif360_lib","title":"load functions — load_aif360_lib","text":"load functions","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/load_aif360_lib.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"load functions — load_aif360_lib","text":"","code":"load_aif360_lib()"},{"path":"https://milevavantuyl.github.io/AIF360/reference/prejudice_remover.html","id":null,"dir":"Reference","previous_headings":"","what":"Prejudice Remover — prejudice_remover","title":"Prejudice Remover — prejudice_remover","text":"Prejudice remover -processing technique adds discrimination-aware regularization term learning objective","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/prejudice_remover.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prejudice Remover — prejudice_remover","text":"","code":"prejudice_remover(eta=1.0, sensitive_attr='',class_attr='')"},{"path":"https://milevavantuyl.github.io/AIF360/reference/prejudice_remover.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prejudice Remover — prejudice_remover","text":"eta fairness penalty parameter sensitive_attr name protected attribute class_attr label name","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/prejudice_remover.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prejudice Remover — prejudice_remover","text":"","code":"if (FALSE) { # An example using the Adult Dataset load_aif360_lib() ad <- adult_dataset() model <- prejudice_remover(class_attr = \"income-per-year\", sensitive_attr = \"race\") model$fit(ad) ad_pred <- model$predict(ad) }"},{"path":"https://milevavantuyl.github.io/AIF360/reference/reject_option_classification.html","id":null,"dir":"Reference","previous_headings":"","what":"Reject option classification — reject_option_classification","title":"Reject option classification — reject_option_classification","text":"Reject option classification  postprocessing technique gives favorable outcomes unpriviliged groups unfavorable outcomes priviliged groups confidence band around decision boundary highest uncertainty.","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/reject_option_classification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reject option classification — reject_option_classification","text":"","code":"reject_option_classification(   unprivileged_groups,   privileged_groups,   low_class_thresh = 0.01,   high_class_thresh = 0.99,   num_class_thresh = as.integer(100),   num_ROC_margin = as.integer(50),   metric_name = \"Statistical parity difference\",   metric_ub = 0.05,   metric_lb = -0.05 )"},{"path":"https://milevavantuyl.github.io/AIF360/reference/reject_option_classification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reject option classification — reject_option_classification","text":"unprivileged_groups list epresentation unprivileged group. privileged_groups list representation privileged group. low_class_thresh Smallest classification threshold use optimization. 0. 1. high_class_thresh Highest classification threshold use optimization. 0. 1. num_class_thresh Number classification thresholds low_class_thresh high_class_thresh optimization search. > 0. num_ROC_margin Number relevant ROC margins used optimization search. > 0. metric_name Name metric use optimization. Allowed options \"Statistical parity difference\", \"Average odds difference\", \"Equal opportunity difference\". metric_ub Upper bound constraint metric value metric_lb Lower bound constraint metric value","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/reject_option_classification.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reject option classification — reject_option_classification","text":"","code":"if (FALSE) { # Example with Adult Dataset load_aif360_lib() ad <- adult_dataset() p <- list(\"race\",1) u <- list(\"race\", 0)  col_names <- c(ad$feature_names, \"label\") ad_df <- data.frame(ad$features, ad$labels) colnames(ad_df) <- col_names  lr <- glm(label ~ ., data=ad_df, family=binomial)  ad_prob <- predict(lr, ad_df) ad_pred <- factor(ifelse(ad_prob> 0.5,1,0))  ad_df_pred <- data.frame(ad_df) ad_df_pred$label <- as.character(ad_pred) colnames(ad_df_pred) <- c(ad$feature_names, 'label')  ad_ds <- binary_label_dataset(ad_df, target_column='label', favor_label = 1,                      unfavor_label = 0, unprivileged_protected_attribute = 0,                      privileged_protected_attribute = 1, protected_attribute='race')  ad_ds_pred <- binary_label_dataset(ad_df_pred, target_column='label', favor_label = 1,                unfavor_label = 0, unprivileged_protected_attribute = 0,                privileged_protected_attribute = 1, protected_attribute='race')  roc <- reject_option_classification(unprivileged_groups = u,                                    privileged_groups = p,                                    low_class_thresh = 0.01,                                    high_class_thresh = 0.99,                                    num_class_thresh = as.integer(100),                                    num_ROC_margin = as.integer(50),                                    metric_name = \"Statistical parity difference\",                                    metric_ub = 0.05,                                    metric_lb = -0.05)  roc <- roc$fit(ad_ds, ad_ds_pred)  ds_transformed_pred <- roc$predict(ad_ds_pred) }"},{"path":"https://milevavantuyl.github.io/AIF360/reference/reweighing.html","id":null,"dir":"Reference","previous_headings":"","what":"Reweighing — reweighing","title":"Reweighing — reweighing","text":"Reweighing preprocessing technique weights examples (group, label) combination differently ensure fairness classification","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/reweighing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reweighing — reweighing","text":"","code":"reweighing(unprivileged_groups, privileged_groups)"},{"path":"https://milevavantuyl.github.io/AIF360/reference/reweighing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reweighing — reweighing","text":"unprivileged_groups list two values: column protected class value indicating representation unprivileged group privileged_groups list two values: column protected class value indicating representation privileged group","code":""},{"path":"https://milevavantuyl.github.io/AIF360/reference/reweighing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reweighing — reweighing","text":"","code":"if (FALSE) { # An example using the Adult Dataset load_aif360_lib() ad <- adult_dataset() p <- list(\"race\", 1) u <- list(\"race\", 0) rw <- reweighing(u,p) rw$fit(ad) ad_transformed <- rw$transform(ad) ad_fit_transformed <- rw$fit_transform(ad) }"}]
